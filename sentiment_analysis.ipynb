{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis**\n",
    "\n",
    "This note is to train 10000 samples using NLTK and Sklearn ML libraries and demonstrate how to build the sentiment model to identify whether the individual article is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the whole thing plays out with the drowsy heaviness of synchronized swimmer wearing a wool wetsuit .', 0), (' . . . with \" the bourne identity \" we return to the more traditional action genre .', 1), ('there ought to be a directing license , so that ed burns can have his revoked .', 0), ('what was subtle and mystifying in the novella is now broad and farcical .', 0), (\"aside from being the funniest movie of the year , simone , andrew niccol's brilliant anti-hollywood satire , has a wickedly eccentric enchantment to it .\", 1)]\n"
     ]
    }
   ],
   "source": [
    "pos_doc = open('positive.txt','rb')\n",
    "neg_doc = open('negative.txt','rb')\n",
    "documents = []\n",
    "for review in pos_doc:\n",
    "    documents.append((review.decode('latin-1').rstrip(), 1))\n",
    "\n",
    "for review in neg_doc:\n",
    "    documents.append((review.decode('latin-1').rstrip(), 0))\n",
    "    \n",
    "random.shuffle(documents)\n",
    "\n",
    "print (documents[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing: normalizing, stemmed, removing stopwords and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118228\n"
     ]
    }
   ],
   "source": [
    "all_corpus_words = []\n",
    "for review, category in documents:\n",
    "    words = [ps.stem(x.lower()) for x in nltk.word_tokenize(str(review))\n",
    "                     if x not in stop_words if x not in punctuations if x != \"''\"]\n",
    "    for word in words:\n",
    "        all_corpus_words.append(word)\n",
    "\n",
    "print (len(all_corpus_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_corpus_words = nltk.FreqDist(all_corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14752\n"
     ]
    }
   ],
   "source": [
    "print (len(all_corpus_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 3537),\n",
       " ('film', 1804),\n",
       " ('movi', 1547),\n",
       " (\"n't\", 940),\n",
       " ('like', 804),\n",
       " ('one', 763),\n",
       " ('--', 670),\n",
       " ('``', 655),\n",
       " ('make', 611),\n",
       " ('stori', 536)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corpus_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 [\"'s\", 'film', 'movi', \"n't\", 'like', 'one', '--', '``', 'make', 'stori']\n"
     ]
    }
   ],
   "source": [
    "word_features = [x for x,y in all_corpus_words.most_common(3000)]\n",
    "print (len(word_features), word_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple bag-of-words model\n",
    "\n",
    "### meaning features = 1/0, True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(review):\n",
    "    features = {}\n",
    "    review_words = set([x.lower() for x in nltk.word_tokenize(str(review)) \n",
    "                     if x not in stop_words if x not in punctuations])\n",
    "    for word in word_features:\n",
    "        features[word] = (word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData = []\n",
    "for review, category in documents:\n",
    "    allData.append((get_features(review), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n"
     ]
    }
   ],
   "source": [
    "print (len(allData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainData, testData = train_test_split(allData, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143 3519\n"
     ]
    }
   ],
   "source": [
    "print (len(trainData), len(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NLTK Naive Bayes classifier training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6706450696220517\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainData)\n",
    "print ('Accuracy:', nltk.classify.accuracy(classifier, testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.670076726342711\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainData)\n",
    "print ('Accuracy:', nltk.classify.accuracy(classifier, testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6609832338732594\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainData)\n",
    "print ('Accuracy:', nltk.classify.accuracy(classifier, testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6572890025575447\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainData)\n",
    "print ('Accuracy:', nltk.classify.accuracy(classifier, testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(get_features(documents[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(get_features(documents[2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    dull = True                0 : 1      =     19.7 : 1.0\n",
      "                    loud = True                0 : 1      =     12.3 : 1.0\n",
      "                      tv = True                0 : 1      =     11.8 : 1.0\n",
      "                    flat = True                0 : 1      =     11.0 : 1.0\n",
      "                      90 = True                0 : 1      =     10.3 : 1.0\n",
      "                  warmth = True                1 : 0      =      9.7 : 1.0\n",
      "                    weak = True                0 : 1      =      9.6 : 1.0\n",
      "                    save = True                0 : 1      =      9.0 : 1.0\n",
      "                   vivid = True                1 : 0      =      8.4 : 1.0\n",
      "                mindless = True                0 : 1      =      8.3 : 1.0\n",
      "                     low = True                0 : 1      =      8.3 : 1.0\n",
      "                    warm = True                1 : 0      =      7.8 : 1.0\n",
      "                  stupid = True                0 : 1      =      7.8 : 1.0\n",
      "                    thin = True                0 : 1      =      7.8 : 1.0\n",
      "                   trite = True                0 : 1      =      7.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Accuracy: 0.6606990622335891\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(trainData)\n",
    "print ('MNB Accuracy:', nltk.classify.accuracy(MNB_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB Accuracy: 0.6564364876385337\n"
     ]
    }
   ],
   "source": [
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(trainData)\n",
    "print ('BNB Accuracy:', nltk.classify.accuracy(BNB_classifier, testData)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.49843705598181304\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(trainData)\n",
    "print ('SVC Accuracy:', nltk.classify.accuracy(SVC_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy: 0.6544472861608411\n"
     ]
    }
   ],
   "source": [
    "LSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LSVC_classifier.train(trainData)\n",
    "print ('Linear SVC Accuracy:', nltk.classify.accuracy(LSVC_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU SVC Accuracy: 0.6337027564649048\n"
     ]
    }
   ],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(trainData)\n",
    "print ('NU SVC Accuracy:', nltk.classify.accuracy(NuSVC_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logsitic Regression Accuracy: 0.6652458084683148\n"
     ]
    }
   ],
   "source": [
    "LogReg_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogReg_classifier.train(trainData)\n",
    "print ('Logsitic Regression Accuracy:', nltk.classify.accuracy(LogReg_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression Accuracy: 0.6354077863029269\n"
     ]
    }
   ],
   "source": [
    "SGD_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGD_classifier.train(trainData)\n",
    "print ('SGD Regression Accuracy:', nltk.classify.accuracy(SGD_classifier, testData)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vote Classifer (majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "        \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(classifier, MNB_classifier, BNB_classifier, \n",
    "                                  SVC_classifier, LSVC_classifier, NuSVC_classifier,\n",
    "                                 LogReg_classifier, SGD_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "no unique mode; found 2 equally common values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-024a39ec4185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'voted classifier Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoted_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/nltk/classify/util.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(classifier, gold)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/nltk/classify/api.py\u001b[0m in \u001b[0;36mclassify_many\u001b[0;34m(self, featuresets)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_classify_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/nltk/classify/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_classify_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-b2a1f04706e9>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/statistics.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise StatisticsError(\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;34m'no unique mode; found %d equally common values'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                 )\n\u001b[1;32m    476\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatisticsError\u001b[0m: no unique mode; found 2 equally common values"
     ]
    }
   ],
   "source": [
    "print ('voted classifier Accuracy:', nltk.classify.accuracy(voted_classifier, testData)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(testData[0][0]), \"Confidence %:\",voted_classifier.confidence(testData[0][0]))\n",
    "print(\"Classification:\", voted_classifier.classify(testData[1][0]), \"Confidence %:\",voted_classifier.confidence(testData[1][0]))\n",
    "print(\"Classification:\", voted_classifier.classify(testData[2][0]), \"Confidence %:\",voted_classifier.confidence(testData[2][0]))\n",
    "print(\"Classification:\", voted_classifier.classify(testData[3][0]), \"Confidence %:\",voted_classifier.confidence(testData[3][0]))\n",
    "print(\"Classification:\", voted_classifier.classify(testData[4][0]), \"Confidence %:\",voted_classifier.confidence(testData[4][0]))\n",
    "print(\"Classification:\", voted_classifier.classify(testData[5][0]), \"Confidence %:\",voted_classifier.confidence(testData[5][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF representation\n",
    "\n",
    "### tf-idf(w,d) = tf (w,d)×(idf(w,d)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(stop_words ='english')\n",
    "bag = count.fit_transform([review for review, sent in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('the whole thing plays out with the drowsy heaviness of synchronized swimmer wearing a wool wetsuit .',\n",
       "  0),\n",
       " ('there ought to be a directing license , so that ed burns can have his revoked .',\n",
       "  0))"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0], documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17829, 16082, 4860]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.37,  0.21,  0.35])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [count.vocabulary_['wool'], count.vocabulary_['thing'], count.vocabulary_['drowsy']]\n",
    "print (a)\n",
    "nlpData_X[0][a[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4406, 9275, 13320]\n",
      "[ 0.  0.  0.]\n",
      "[ 0.37  0.42  0.47]\n"
     ]
    }
   ],
   "source": [
    "b = [count.vocabulary_['directing'], count.vocabulary_['license'], count.vocabulary_['revoked']]\n",
    "print (b)\n",
    "print (nlpData_X[0][b[:]])\n",
    "print (nlpData_X[2][b[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4860 0.353\n",
      "7420 0.368\n",
      "11828 0.235\n",
      "15721 0.368\n",
      "15765 0.368\n",
      "16082 0.206\n",
      "17558 0.315\n",
      "17631 0.368\n",
      "17829 0.368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "tfidf = TfidfTransformer()\n",
    "nlpData_X = tfidf.fit_transform(bag).toarray()\n",
    "for i in range(len(nlpData_X[0])):\n",
    "    if nlpData[0][i] !=0:\n",
    "        print (i, round(nlpData_X[0][i],3))\n",
    "#print([x for x in nlpData_X[0] if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35285352530236758, 0.36844539502206186, 0.23457680596107855, 0.36844539502206186, 0.36844539502206186, 0.20590553705369649, 0.31513644034386545, 0.36844539502206186, 0.36844539502206186]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=True,preprocessor=None, stop_words ='english')\n",
    "nlpData_X = tfidf.fit_transform([review for review, sent in documents]).toarray()\n",
    "print ([x for x in nlpData_X[0] if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10662, 18041), 14752)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpData_X.shape, len(all_corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        #self.wnl = WordNetLemmatizer()\n",
    "        self.wnl = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.stem(t) for t in word_tokenize(doc) if t not in punctuations]\n",
    "\n",
    "stemmedCount = CountVectorizer(tokenizer=LemmaTokenizer(),stop_words ='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 14655)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmedBag = stemmedCount.fit_transform([review for review, y in documents])\n",
    "stemmedTfidf = TfidfTransformer()\n",
    "nlpData2_X = stemmedTfidf.fit_transform(stemmedBag).toarray()\n",
    "nlpData2_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After stemmed, the variety in verb tense and noun formst no longer exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, False)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'synchronized' in stemmedCount.vocabulary_, 'plays' in stemmedCount.vocabulary_, 'revoked' in stemmedCount.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because in the **CountVectorizer** function we have implemented **LemmaTokenizer** to stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('synchron', 'play', 'revok')"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('synchronized'), PorterStemmer().stem('plays'), PorterStemmer().stem('revoked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'synchron' in stemmedCount.vocabulary_, 'play' in stemmedCount.vocabulary_, 'revok' in stemmedCount.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12707, 9690, 10719]\n",
      "[ 0.39  0.21  0.  ] [ 0.    0.    0.48]\n"
     ]
    }
   ],
   "source": [
    "c = [stemmedCount.vocabulary_['synchron'], stemmedCount.vocabulary_['play'], stemmedCount.vocabulary_['revok']]\n",
    "print (c)\n",
    "print (nlpData2_X[0][c[:]], nlpData2_X[2][c[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmedTfidf = TfidfVectorizer(strip_accents=None,lowercase=True,preprocessor=None, stop_words ='english', tokenizer=LemmaTokenizer(),)\n",
    "nlpData3_X = stemmedTfidf.fit_transform([review for review, y in documents]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10662, 14655), numpy.ndarray)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpData3_X.shape, type(nlpData3_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlpData3_y = np.array([y for review, y in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7143, 14655), (3519, 14655))"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(nlpData3_X, nlpData3_y, test_size=0.33)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89976200475990475"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74822392725206022"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 0.503009735363\n",
      "0.01 0.696768721475\n",
      "0.1 0.733025797732\n",
      "1 0.755989304813\n",
      "2 0.759488354782\n",
      "3 0.759769250357\n",
      "4 0.759208830385\n",
      "5 0.759069753776\n",
      "7 0.757249025484\n",
      "10 0.757388102094\n",
      "20 0.753607177137\n",
      "Best parameter = 3  , accuracy (R^2) =  0.749076442171\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "best_logreg_model = None\n",
    "max_score = -1\n",
    "best_reg = -1\n",
    "for regularization_param in [1e-6, 0.01, 0.1, 1, 2, 3, 4, 5, 7, 10, 20]:\n",
    "    logreg = linear_model.LogisticRegression('l2', C=regularization_param)\n",
    "    cv_score = cross_val_score(logreg, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    print (regularization_param, np.mean(cv_score))\n",
    "    if np.mean(cv_score) > max_score:\n",
    "        max_score = np.mean(cv_score)\n",
    "        best_logreg_model = logreg\n",
    "        best_reg = regularization_param\n",
    "        \n",
    "best_logreg_model.fit(X_train, y_train)\n",
    "prediction = best_logreg_model.predict(X_test)\n",
    "print ('Best parameter =', best_reg, ', accuracy (R^2) = ', best_logreg_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5,rc={\"lines.linewidth\": 3})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21d461ac8>"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAGZCAYAAAD2EimWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npjzwFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d351cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_y_train_prob = best_logreg_model.predict_proba(X_train)\n",
    "logreg_y_test_prob = best_logreg_model.predict_proba(X_test)\n",
    "\n",
    "fpr_train, tpr_train, _ = metrics.roc_curve(y_train, logreg_y_train_prob[:,1])\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "\n",
    "fpr_test, tpr_test, _ = metrics.roc_curve(y_test, logreg_y_test_prob[:,1])\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_train, tpr_train, color = 'b')\n",
    "plt.plot(fpr_test, tpr_test, color = 'r')   #m: magenta\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves for classifiers')\n",
    "\n",
    "blue_line = mlines.Line2D([], [], color='blue', label='training Data (area = %0.2f)' % roc_auc_train)\n",
    "red_line = mlines.Line2D([], [], color='red', label='test Data (area = %0.2f)' % roc_auc_test)\n",
    "\n",
    "plt.legend(handles=[blue_line, red_line],loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.658425689116\n",
      "20.319674968719482\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print ('ACC:', rf.score(X_test, y_test))\n",
    "print (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  46.4s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  44.8s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  41.5s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  39.7s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  33.1s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  34.6s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  29.7s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  35.2s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  33.8s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  52.9s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=10 -  31.8s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  52.0s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  54.0s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 - 1.0min[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  54.5s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 - 1.0min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  59.5s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 - 1.0min[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 -  57.4s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=10 - 1.0min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.4min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.3min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.5min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.4min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.6min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.6min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.6min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.5min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.5min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 2.2min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=10 - 1.6min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 2.2min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 2.1min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.9min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 2.1min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.9min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.8min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.8min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.8min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=10 - 1.9min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.7min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.7min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.7min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.4min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.6min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.4min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=700, max_depth=5, min_samples_leaf=10 ..............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.8min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.6min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=10 - 2.8min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............\n",
      "\n",
      "\n",
      "\n",
      "[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.2min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.8min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.3min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.8min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=10 .............\n",
      "\n",
      "\n",
      "\n",
      "[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.9min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.9min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.9min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=10 - 3.8min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  32.5s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  43.7s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  27.1s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  46.5s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 .............."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-478-24387d9a01d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'min_samples_leaf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_cv_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_cv_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mbest_rf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cv_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 for train, test in cv)\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hhhung/anaconda/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  31.1s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  45.0s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  30.1s[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  42.9s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  26.4s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 - 1.1min[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  26.0s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 - 1.1min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  30.0s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 - 1.0min[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  30.5s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 - 1.0min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=100, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  25.6s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 -  54.9s[CV] ..... n_estimators=100, max_depth=5, min_samples_leaf=20 -  25.7s[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 -  54.6s\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  45.1s[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.6min[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  47.1s[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  41.0s[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.6min[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  42.7s[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=200, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  50.3s[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.3min[CV] ..... n_estimators=200, max_depth=5, min_samples_leaf=20 -  50.6s[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.2min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 -  53.8s[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.3min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 -  53.7s[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.3min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=300, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 - 1.0min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.2min[CV] ..... n_estimators=300, max_depth=5, min_samples_leaf=20 -  60.0s[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.3min\n",
      "\n",
      "\n",
      "\n",
      "[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............\n",
      "\n",
      "\n",
      "\n",
      "[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.4min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.4min\n",
      "\n",
      "[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.8min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.7min\n",
      "\n",
      "[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=500, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.4min[CV] ..... n_estimators=500, max_depth=5, min_samples_leaf=20 - 1.5min\n",
      "\n",
      "[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.4min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.4min\n",
      "\n",
      "[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............[CV] n_estimators=700, max_depth=5, min_samples_leaf=20 ..............\n",
      "\n",
      "[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.2min[CV] ..... n_estimators=700, max_depth=5, min_samples_leaf=20 - 2.1min\n",
      "\n",
      "[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............\n",
      "\n",
      "[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=20 - 3.4min[CV] .... n_estimators=1000, max_depth=5, min_samples_leaf=20 - 3.3min\n",
      "\n",
      "[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............[CV] n_estimators=1000, max_depth=5, min_samples_leaf=20 .............\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [100, 200, 300, 500, 700, 1000],'max_depth':[5,10,15],'min_samples_leaf':[10,20]}\n",
    "model_cv_grid = grid_search.GridSearchCV(rf,parameters,scoring='roc_auc',verbose=2,n_jobs=-1, cv =10)\n",
    "model_cv_grid.fit(X_train,y_train)\n",
    "best_rf_model = model_cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
