{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python NLP Libraryies Implmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence1 = \"At eight on Thursday morning Arthur felt very very good, but not perfect.\"\n",
    "sentence2 = \"Thursday night is good\"\n",
    "sentence3 = \"Arthur is is feeling good at eight\"\n",
    "paragraph = \"At eight on Thursday morning Arthur felt very very good, but not prefect. Thursday night is good! Although Arthur is is feeling good at eight.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['At eight on Thursday morning Arthur felt very very good, but not prefect.', 'Thursday night is good!', 'Although Arthur is is feeling good at eight']\n"
     ]
    }
   ],
   "source": [
    "print (type(nltk.sent_tokenize(paragraph)), nltk.sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at eight on thursday morning arthur felt very very good, but not perfect.\n"
     ]
    }
   ],
   "source": [
    "sentence1 = sentence1.lower()\n",
    "print (sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['at', 'eight', 'on', 'thursday', 'morning', 'arthur', 'felt', 'very', 'very', 'good', ',', 'but', 'not', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentence1)\n",
    "print (type(words), words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', 'on', 'thursday', 'morning', 'arthur', 'felt', 'very', 'very', 'good', 'but', 'not', 'perfect']\n"
     ]
    }
   ],
   "source": [
    "print ([x for x in words if x not in punctuations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eight', 'thursday', 'morning', 'arthur', 'felt', 'good', ',', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "print ([x for x in words if x not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', 'on', 'thursday', 'morn', 'arthur', 'felt', 'veri', 'veri', 'good', ',', 'but', 'not', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "print ([ps.stem(x) for x in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here the porter stemmer is unable to detect 'felt' with stemmed 'feel'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eight', 'thursday', 'morn', 'arthur', 'felt', 'good', 'perfect']\n"
     ]
    }
   ],
   "source": [
    "print ([ps.stem(x.lower()) for x in words if x not in punctuations if x not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the word space is smaller than directly word tokenizing the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Feature Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At eight on Thursday morning Arthur felt very very good, but not prefect. Thursday night is good! Although Arthur is is feeling good at eight.\n"
     ]
    }
   ],
   "source": [
    "print (paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At eight on Thursday morning Arthur felt very very good, but not prefect.\n",
      "Thursday night is good!\n",
      "Although Arthur is is feeling good at eight.\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for sentence in nltk.sent_tokenize(paragraph):\n",
    "    print (sentence)\n",
    "    all_words += [ps.stem(x.lower()) for x in nltk.word_tokenize(sentence) \n",
    "                 if x not in punctuations if x not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', 'thursday', 'morn', 'arthur', 'felt', 'good', 'prefect', 'thursday', 'night', 'good', 'although', 'arthur', 'feel', 'good', 'eight']\n"
     ]
    }
   ],
   "source": [
    "print (all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(review):\n",
    "    features = {}\n",
    "    review_words = set([x.lower() for x in nltk.word_tokenize(str(review)) \n",
    "                     if x not in stop_words if x not in punctuations])\n",
    "    for word in all_words:\n",
    "        features[word] = (word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic representaiton (0/1) for feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'good': True, 'eight': True, 'felt': True, 'prefect': True, 'night': False, 'arthur': True, 'although': False, 'thursday': True, 'at': True, 'feel': False, 'morn': False}\n",
      "2 {'good': True, 'eight': False, 'felt': False, 'prefect': False, 'night': True, 'arthur': False, 'although': False, 'thursday': True, 'at': False, 'feel': False, 'morn': False}\n",
      "3 {'good': True, 'eight': True, 'felt': False, 'prefect': False, 'night': False, 'arthur': True, 'although': True, 'thursday': False, 'at': False, 'feel': False, 'morn': False}\n"
     ]
    }
   ],
   "source": [
    "sent =1\n",
    "for sentence in nltk.sent_tokenize(paragraph):\n",
    "    print (sent, get_features(sentence))\n",
    "    sent +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sklearn: TF-IDF representation\n",
    "\n",
    "### $$\\textrm{tf-idf(w,d)} = \\textrm{tf (w,d)}\\times (\\textrm{idf(w,d)}+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 TF (term frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "doc = np.array([sentence1, sentence2, sentence3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight': 5, 'very': 15, 'feeling': 6, 'Thursday': 2, 'not': 12, 'morning': 10, 'but': 4, 'Arthur': 0, 'on': 13, 'At': 1, 'night': 11, 'at': 3, 'good': 8, 'is': 9, 'perfect': 14, 'felt': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase=False)  \n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight': 3, 'very': 14, 'feeling': 4, 'night': 9, 'on': 11, 'thursday': 13, 'arthur': 0, 'not': 10, 'morning': 8, 'at': 1, 'good': 6, 'but': 2, 'is': 7, 'perfect': 12, 'felt': 5}\n"
     ]
    }
   ],
   "source": [
    "'''The deault to use CountVectorizer is lowercase = True'''\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feeling': 1, 'night': 5, 'arthur': 0, 'thursday': 7, 'morning': 4, 'good': 3, 'perfect': 6, 'felt': 2}\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'At eight on Thursday morning Arthur felt very very good, but not perfect.'\n",
      " 'Thursday night is good' 'Arthur is is feeling good at eight']\n"
     ]
    }
   ],
   "source": [
    "print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 1 0 1 1]\n",
      " [0 0 0 1 0 1 0 1]\n",
      " [1 1 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 n-gram representation (n>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twograms = CountVectorizer(ngram_range=(1,2), stop_words ='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feeling': 3, 'thursday': 14, 'morning': 9, 'arthur feeling': 1, 'felt good': 6, 'thursday night': 16, 'thursday morning': 15, 'night good': 12, 'feeling good': 4, 'arthur felt': 2, 'night': 11, 'arthur': 0, 'good perfect': 8, 'morning arthur': 10, 'good': 7, 'perfect': 13, 'felt': 5}\n"
     ]
    }
   ],
   "source": [
    "bag = twograms.fit_transform(doc)\n",
    "print (twograms.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1]\n",
      " [1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 TF-IDF representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Using CountVectorizer( ) + TfidfTransformer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36  0.    0.47  0.28  0.47  0.    0.47  0.36]\n",
      " [ 0.    0.    0.    0.43  0.    0.72  0.    0.55]\n",
      " [ 0.55  0.72  0.    0.43  0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "tfidf = TfidfTransformer()  ## this bag is normalized and removes stop words.\n",
    "np.set_printoptions(precision=2)\n",
    "print(tfidf.fit_transform(bag).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Using TfidfVectorizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36  0.    0.47  0.28  0.47  0.    0.47  0.36]\n",
      " [ 0.    0.    0.    0.43  0.    0.72  0.    0.55]\n",
      " [ 0.55  0.72  0.    0.43  0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=True,preprocessor=None, stop_words ='english')\n",
    "print(tfidf.fit_transform(doc).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
