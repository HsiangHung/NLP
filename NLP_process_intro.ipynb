{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python NLP Library Implmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence1 = \"At eight on Thursday morning Arthur felt very good good, but not perfect.\"\n",
    "sentence2 = \"Thursday night is good!\"\n",
    "sentence3 = \"Although Arthur is is feeling good at eight feel\"\n",
    "article = \"At eight on Thursday morning Arthur felt very good good, but not prefect. Thursday night is good! Although Arthur is is feeling good at eight feel.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['At eight on Thursday morning Arthur felt very good good, but not prefect.', 'Thursday night is good!', 'Although Arthur is is feeling good at eight feel.']\n"
     ]
    }
   ],
   "source": [
    "print (type(nltk.sent_tokenize(article)), nltk.sent_tokenize(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalization\n",
    "\n",
    "Unify all words in lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at eight on thursday morning arthur felt very good good, but not perfect.\n"
     ]
    }
   ],
   "source": [
    "sentence1 = sentence1.lower()\n",
    "print (sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['at', 'eight', 'on', 'thursday', 'morning', 'arthur', 'felt', 'very', 'good', 'good', ',', 'but', 'not', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentence1)\n",
    "print (type(words), words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'^', '|', '~', '{', ':', ';', '=', '}', '\\\\', '%', '>', '.', '!', '+', '#', '?', '*', ')', '(', \"'\", '&', '[', ']', '@', '-', '`', ',', '<', '\"', '/', '$', '_'}\n"
     ]
    }
   ],
   "source": [
    "print (punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', 'on', 'thursday', 'morning', 'arthur', 'felt', 'very', 'good', 'good', 'but', 'not', 'perfect']\n"
     ]
    }
   ],
   "source": [
    "print ([x for x in words if x not in punctuations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'between', 'below', 'ain', 'me', 'off', 'doesn', 'while', 'out', 'my', 'where', 'and', 'our', 'how', 'some', 'after', 'such', 'nor', 'same', 'himself', 'all', 'weren', 'mustn', 'to', 'can', 'mightn', 'needn', 'hers', 'for', 'will', 'o', 'then', 'few', 'she', 'wasn', 'has', 'each', 'with', 'in', 'is', 's', 'have', 'm', 'having', 'what', 'whom', 'not', 'those', 'do', 'ourselves', 'his', 'ma', 'against', 'we', 'ours', 'your', 'it', 'its', 'these', 'at', 'by', 'into', 'too', 'theirs', 'no', 'he', 'aren', 'over', 're', 'yours', 'now', 'but', 'down', 'their', 'who', 'both', 'because', 'most', 'so', 'as', 'only', 'll', 'on', 'itself', 'didn', 'won', 'am', 'an', 'than', 'of', 'hasn', 'hadn', 'which', 'they', 'there', 'be', 'i', 'if', 'once', 'until', 'up', 'further', 'a', 'own', 'shouldn', 'were', 'yourself', 'above', 'that', 'shan', 'before', 'through', 'him', 'her', 'this', 'wouldn', 'did', 'had', 'myself', 'should', 'isn', 'just', 'does', 'yourselves', 'the', 'under', 'been', 'when', 'you', 'why', 'd', 'or', 'very', 'them', 'more', 'themselves', 'during', 'about', 'don', 'from', 'herself', 'other', 'y', 'being', 'are', 've', 'again', 'doing', 't', 'couldn', 'here', 'haven', 'was', 'any'}\n"
     ]
    }
   ],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eight', 'thursday', 'morning', 'arthur', 'felt', 'good', 'good', ',', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "print ([x for x in words if x not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Stemming\n",
    "\n",
    "Turning all verb's tenses to present tense and plural nouns to singular noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', 'on', 'thursday', 'morn', 'arthur', 'felt', 'veri', 'good', 'good', ',', 'but', 'not', 'perfect', '.']\n"
     ]
    }
   ],
   "source": [
    "print ([ps.stem(x) for x in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here the porter stemmer is unable to detect 'felt' with stemmed 'feel', so the porter stemmer doesn't work perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight', 'arthur', 'thursday', 'morn', 'good', 'perfect', 'felt'}\n"
     ]
    }
   ],
   "source": [
    "print (set([ps.stem(x.lower()) for x in words if x not in punctuations if x not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the word space is smaller than directly word tokenizing the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Feature Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At eight on Thursday morning Arthur felt very good good, but not prefect. Thursday night is good! Although Arthur is is feeling good at eight feel.\n"
     ]
    }
   ],
   "source": [
    "print (article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at eight on thursday morning arthur felt very good good, but not prefect.\n",
      "['eight', 'thursday', 'morn', 'arthur', 'felt', 'good', 'good', 'prefect']\n",
      "thursday night is good!\n",
      "['thursday', 'night', 'good']\n",
      "although arthur is is feeling good at eight feel.\n",
      "['although', 'arthur', 'feel', 'good', 'eight', 'feel']\n"
     ]
    }
   ],
   "source": [
    "all_corpus_words = []\n",
    "for sentence in nltk.sent_tokenize(article.lower()):\n",
    "    print (sentence)\n",
    "    words = [ps.stem(x) for x in nltk.word_tokenize(sentence) \n",
    "                 if x not in punctuations if x not in stop_words]\n",
    "    all_corpus_words += words\n",
    "    print (words)\n",
    "    \n",
    "all_corpus_words = set(all_corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight', 'prefect', 'night', 'arthur', 'although', 'thursday', 'feel', 'morn', 'good', 'felt'}\n"
     ]
    }
   ],
   "source": [
    "print (all_corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(review):\n",
    "    features = {}\n",
    "    review_words = set([x.lower() for x in nltk.word_tokenize(str(review)) \n",
    "                     if x not in stop_words if x not in punctuations])\n",
    "    for word in all_words:\n",
    "        features[word] = (word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Basic representaiton (0/1) for feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'good': True, 'eight': True, 'felt': True, 'feel': False, 'night': False, 'arthur': True, 'although': False, 'thursday': True, 'prefect': True, 'morn': False}\n",
      "2 {'good': True, 'eight': False, 'felt': False, 'feel': False, 'night': True, 'arthur': False, 'although': False, 'thursday': True, 'prefect': False, 'morn': False}\n",
      "3 {'good': True, 'eight': True, 'felt': False, 'feel': True, 'night': False, 'arthur': True, 'although': True, 'thursday': False, 'prefect': False, 'morn': False}\n"
     ]
    }
   ],
   "source": [
    "sent =1\n",
    "for sentence in nltk.sent_tokenize(article):\n",
    "    print (sent, get_features(sentence))\n",
    "    sent +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sklearn: TF-IDF representation\n",
    "\n",
    "## $$\\textrm{tf-idf(w,d)} = \\textrm{tf (w,d)}\\times (\\textrm{idf(w,d)}+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 TF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "doc = np.array([sentence1, sentence2, sentence3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight': 6, 'very': 18, 'feeling': 8, 'thursday': 17, 'Thursday': 2, 'not': 14, 'morning': 12, 'but': 5, 'Arthur': 1, 'Although': 0, 'on': 15, 'night': 13, 'arthur': 3, 'feel': 7, 'at': 4, 'good': 10, 'is': 11, 'perfect': 16, 'felt': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(lowercase=False)  \n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight': 4, 'very': 16, 'feeling': 6, 'although': 0, 'thursday': 15, 'not': 12, 'morning': 10, 'but': 3, 'on': 13, 'night': 11, 'arthur': 1, 'feel': 5, 'at': 2, 'good': 8, 'is': 9, 'perfect': 14, 'felt': 7}\n"
     ]
    }
   ],
   "source": [
    "'''The deault to use CountVectorizer is lowercase = True'''\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feeling': 2, 'night': 6, 'arthur': 0, 'thursday': 8, 'morning': 5, 'good': 4, 'feel': 1, 'perfect': 7, 'felt': 3}\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "bag = count.fit_transform(doc)\n",
    "print (count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eight', 'prefect', 'night', 'arthur', 'although', 'thursday', 'feel', 'morn', 'good', 'felt'}\n"
     ]
    }
   ],
   "source": [
    "print (all_corpus_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here the sklearn's CountVector also remvoed words **although** and **eight**, but previously we implemented stemmer so there is no **feeling** in **all_corpus_words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'At eight on Thursday morning Arthur felt very very good, but not perfect.'\n",
      " 'Thursday night is good!' 'Although Arthur is is feeling good at eight']\n"
     ]
    }
   ],
   "source": [
    "print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 2 1 0 1 1]\n",
      " [0 0 0 0 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 n-gram representation (n>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twograms = CountVectorizer(ngram_range=(1,2), stop_words ='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feeling': 4, 'thursday': 17, 'morning': 12, 'arthur feeling': 1, 'felt good': 7, 'thursday night': 19, 'thursday morning': 18, 'night good': 15, 'feeling good': 5, 'arthur felt': 2, 'night': 14, 'arthur': 0, 'good perfect': 11, 'feel': 3, 'morning arthur': 13, 'good good': 10, 'good': 8, 'perfect': 16, 'felt': 6, 'good feel': 9}\n"
     ]
    }
   ],
   "source": [
    "bag = twograms.fit_transform(doc)\n",
    "print (twograms.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 1 2 0 1 1 1 1 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1]\n",
      " [1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 TF-IDF representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 TfidfTransformer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32  0.    0.    0.42  0.5   0.42  0.    0.42  0.32]\n",
      " [ 0.    0.    0.    0.    0.43  0.    0.72  0.    0.55]\n",
      " [ 0.44  0.58  0.58  0.    0.35  0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "tfidf = TfidfTransformer()  ## this bag is normalized and removes stop words.\n",
    "np.set_printoptions(precision=2)\n",
    "print(tfidf.fit_transform(bag).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Using TfidfVectorizer( ) = CountVectorizer( ) + TfidfTransformer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32  0.    0.    0.42  0.5   0.42  0.    0.42  0.32]\n",
      " [ 0.    0.    0.    0.    0.43  0.    0.72  0.    0.55]\n",
      " [ 0.44  0.58  0.58  0.    0.35  0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=True,preprocessor=None, stop_words ='english')\n",
    "print(tfidf.fit_transform(doc).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feeling': 2, 'night': 6, 'arthur': 0, 'thursday': 8, 'morning': 5, 'good': 4, 'feel': 1, 'perfect': 7, 'felt': 3}\n",
      "[[1 0 0 1 2 1 0 1 1]\n",
      " [0 0 0 0 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (count.vocabulary_)\n",
    "print (bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'at eight on thursday morning arthur felt very good good, but not perfect.',\n",
       "       'Thursday night is good!',\n",
       "       'Although Arthur is is feeling good at eight feel'], \n",
       "      dtype='<U73')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4, 7, 6]\n",
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "index = [count.vocabulary_['thursday'], count.vocabulary_['good'], count.vocabulary_['perfect'],count.vocabulary_['night']]\n",
    "print (index)\n",
    "print (bag.toarray()[0][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Overall article in terms of tfidf reprentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_tfidf = tfidf.fit_transform([x for x in nltk.sent_tokenize(article)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32  0.    0.    0.42  0.5   0.42  0.    0.42  0.32]\n",
      " [ 0.    0.    0.    0.    0.43  0.    0.72  0.    0.55]\n",
      " [ 0.44  0.58  0.58  0.    0.35  0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32  0.5   0.42  0.  ]\n"
     ]
    }
   ],
   "source": [
    "print (doc_tfidf.toarray()[0][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
